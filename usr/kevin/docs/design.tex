\documentclass[11pt]{article}

% The following gives 21mm margin on all sides.

\setlength{\hoffset}{-1.0in}
\setlength{\voffset}{-1.0in}

\setlength{\headheight}{0.0cm}
\setlength{\headsep}{0.0cm}
\setlength{\topmargin}{3.1cm}
\setlength{\evensidemargin}{2.6cm}
\setlength{\oddsidemargin}{2.6cm}

\setlength{\textwidth}{15.8cm}
\setlength{\textheight}{22.9cm}

\setlength{\footskip}{0.7cm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{\smallskipamount}

\usepackage{graphics}
\usepackage{graphicx}
\usepackage{epsf}
\usepackage{epic}

\begin{document}

%\frenchspacing

\section{Overview}

\subsection{Aim}

The aim of the software is to provide:
\begin{enumerate}
\item a portable framework for FFS calculations independent
(as far as possible) of the exact details of the simulation
method or code used;
\item serial FFS calculations with serial simulation, and
serial FFS caluclations with (MPI based) parallel simulation;
\item trivially parallel FFS calculations, i.e.,  several independent
FFS ``instances'' running concurrently, the statistics for which are
collated at the end; serial or parallel simulation;
\item non-trivial parallelism, i.e., a single FFS instance
decomposed in parallel; serial or parallel simulation;
\item To provide at least direct and branched FFS implementations;
\end{enumerate}

\subsubsection{Specific targets}

A number of target applications have been identified:

\begin{enumerate}
\item A relatively simple test problem in which the simulation is
serial, e.g., Gillespie algorithm for the genetic switch problem.
\item A more heavyweight application for molecular dynamcs. This
will be LAMMPS, applied to enamtiomer formation. This simulation
may be serial or require small-scale parallelism.
\item A simulation with large-scale MPI parallelism. For this we
will use the lattice Boltzmann via \textit{Ludwig}, applied to
a liquid crystal problem.
\end{enumerate}


\subsection{Architecture}

\subsubsection{Overview}

We aim to produce a single executable model, in which it is imagined
that overall program control will be exerted by FFS, called directly
after the initialisaition of message passing. FFS will be responisble
for driving the necessary simulations ultimately required for the
calculation. This means the simulation must be available as a
linkable library. The abstraction of the simulation used to allow
coupling between a given FFS instance and the simulation code is discussed
below. At the highest level, we have a heirachy of MPI communicators
as shown schematically in Figures~\ref{fig:controller} and~\ref{fig:instance}.
These are responsible for encapsulating communications related to different
aspects of the computation. We consider each component in turn.

\subsubsection{FFS Controller}

The FFS controller must be responsible for overall program control,
while actual the FFS calculation is delegated to an FFS instance.
It is responsible for managing input to FFS, and the distribution
of that input to FFS instance or instances. It may also need to
collating overall output if more than one FFS instance is used.
It will accept a single 'master' random number seed which will
ultimately control all other random number generation in the FFS
process (and simulations). This will allow different statistical
samples to be collected within undue intervention in the code.



\begin{figure}[t]
\label{fig:controller}
\begin{center}
\input{./arch3.epic}
\end{center}
\caption{FFS Controller: A heirachy of MPI communicators will be
employed as containers for communiction related to different
levels of the FFS process. Within \texttt{MPI\_COMM\_WORLD},
the controller is expected to drive one or more independent
instances of the FFS calculation (here just one is illustrated).
In each case, the FFS instance is responsible for the implementation
of the appropriate FFS algorithm. The reults may be collected by the
controller at the end of execution, and appropriate aggregate
statistics can be computed. At this level, there is no attempt
to load balance between the independent instances of FFS.}
\end{figure}

\subsubsection{FFS Instance}


This is responsible for control of the overall FFS workflow. It should
accept input which specifies the details of algorithm to be used
(direct or branched, etc.), and the details of the number and poistion
of the order parameter interfaces, with associated parameters on the
number of trials, pruning probability and so on for each interface.
A single FFS instance will be able to run one or more simulation
instances, which are responisble for running trials forward in
time (to either fixed time, or fixed $\lambda$).


\subsubsection{Simulation Interface}

To meet the requirement that the FFS library be independent of
any particular simulation code, we introduce a layer to
abstract the actions that a simulation is required to perform.
To use a simulation code, an implementation of the interface
must be provided appropriate for the code in question. This
allows the necessary exchange of information between the FFS
instance and the actual simulation. In this way we do not require
intervention in existing simulation code.

DETAILS



\subsubsection{Simulation}

This is reponsible for advancing the state in time, and computing
a relevant order parameter from the simulation state. It need have
no knowledge of the FFS, although it must clearly be able to
support the operations required be the interface. For a simulation
that has no MPI parallel capability, it is expected that the
interface layer will be able to support any necessary action
appropriate for a single MPI task.



\begin{figure}[t]
\label{fig:instance}
\begin{center}
\input{./arch4.epic}
\end{center}
\caption{FFS Instance: Within a given FFS instance, one or more independent
simulation instances may be used to generate trials required by the FFS
algorithm. To separate messages related to FFS, and those within the
simulation code itself, two communicators are used for each simulation
instance, as represeented above. A given FFS instance may try to balance
the trial load between the different simulation instances.}
\end{figure}

\subsubsection{Error Handling}

This is a fraught issue. Many MPI applications have little recourse
other than to call \texttt{MPI\_Abort()} on encountering an error
(e.g., if a required file is not found, or some numerical condition
is violated). In designing an implementing a library to do FFS, we
have tried to account for at least the possibility that a simulation
may return from an error in a controlled way. This would allow a number
of outcomes: (1) a controlled exit from FFS, possibly saving up-to-date
information; (2) continued execution on remaining FFS instances or
simulation instances.

Handling errors in this fashion requires some care to avoid deadlocks
caused by different paths through the code. This requires additional
synchronisation within given communicators. As such synchronisation
comes at a cost in time, we have only introduced such checks in
non-performance critical regions. In this way we aim to trap commonly
occuring error types (e.g., problems handling external files) and
recognise that complete termination via \texttt{MPI\_Abort()} may
not be avoidable in some circumstances. This
situation may improve with enhanced error handling in future versions
of the MPI standard [REFERENCE?].


\subsubsection{Serial Execution}

We note that for serial execution, this picture collapses to a single
FFS instance running a single simulation instance on one MPI task. If
an MPI implementation is not available on a given platform, we provide
a 'dummy' implmentation which will allow the code to be built and run
in a serial fashion.

\section{Example: Gillespie Problem}


\section{Parallel Example: LAMMPS}



\section{Detailed Requirements}

The user will be concerned with specifying the details of the FFS
algorithm and related choices, and the particular parameters for
the simulation at hand. The user should not be concerned with the
details of scheduling, and the controller, which are the rightful
concerns of the developer. We set out here the requirements from
the user's view point.

\subsection{User Requirements}

\subsubsection{FFS Method}
\begin{itemize}
\item
MUST: Allow the user to specify a set of interfaces $\lambda_i$ explicitly
via an appropriate input mechnaism.
\item
MUST: Allow reconstruction of trajectories from stored pathway information.
\item
SHOULD: Allow the user to specify a set of evenly spaced interfaces
implicitly, by specifying the number of interfaces, and $\lambda_{min}$
and $\lambda_{max}$.
\item
COULD: Allow the user some automatic choice, or dynamic repositioning, of
interfaces via appropriate algorithm given $\lambda_{}$ and $\lambda_{max}$.
\item
SHOULD: Allow the user to specify an intial 'relaxation' run period, or
start immediately from a pre-specified initial state.
\item
SHOULD: Allow the user to specify the number of configurations to be used
at the first interface.
\item
MUST: Allow the user to specify whether direct or branched FFS is required.
\item
MUST: Do ``t-if'' non-stationary method
\item
MUST: Allow the user to specify the number of trials involved.
\item
MUST: Allow the user to specify a maximum simulation time for any trial
(which will include a description of what time means for the simulation,
e.g., integer number of steps, or floating point time interval in given
units).
\item
COULD: Provide the user with histograms of the sampling of order parameter
space by trial runs; these can be used to reconstruct the steady state
probability density function of the order parameter. % code exists
\item
COULD: Allow the user to generate a small number (e.g., 10--20 trajectories
from initial to final state) for mechanistic analysis without output of the
full-blown FFS analysis (rate constants etc.).
\item
COULD: Allow the user to `prune' trajectories which return to a previous
interface thus avoiding the need to simulate long paths backwards in
order parameter space. % code exists
\item
COULD: Allow automatic extraction of commitor values for configurations
among stored trajectories (e.g., for analysis of the transition state
ensemble).
\item
COULD: Allow the user to choose the Rosenbluth path sampling method to
obtain unbranched paths with associated statistical weights.
\item
COULD: Provide the user with information on the sampling of configuration
space at different interfaces, i.e., the degree of path branching.
Example: for a given final state $B$, which initial state did this come from?
\item
COULD: Provide the user with information on the variability in
probability of success among configurations at the same interface
(which might be indicative of good or bad choice of order parameter).
These data could suggest better choices for the order parameter.
\item
COULD: Allow the user to optimise the positioning of interfaces
and number of trials per interface by running a short FFS simulations
and using the data obtained (i.e., the probability of success at a
given interface) to suggest better parameter choices (automatically).
See Berero and Escabedo \cite{}.
\end{itemize}

\subsubsection{Parallelism}
\begin{itemize}
\item
MUST: Allow the user the choice of running in FFS serial, or in parallel.
\item
MUST: Allow the user to specify the number of FFF 'instances' which will
run in parallel, and how many MPI tasks each instance will have.
\item
MUST: Allow the user to specify if the simulation will run in parallel
or not (does it take an MPI communicator?), and if so, on how many
MPI tasks.
\item
COULD: Provide user control of whether dynamic load balance is attempted
or not.
\end{itemize}

\subsubsection{Miscellaneous}

\begin{itemize}
\item
MUST: The user must be able to extract appropriate statistical information
in aggregate form.
\item
SHOULD: Allow some level of control of the detail of statistical output.
\item
SHOULD: Allow the user to split a single FFS calculation into successive
jobs. That is, the user should be able to 'restart' from a saved state
if the total run time is expected to be large.
\end{itemize}

\subsubsection{Simulation}


\subsection{Developer Requirements}


\subsection{Controller}




\end{document}
